integrations:
- integration_type: git_repo
  git_repo: sashaDoubov/llm-foundry
  git_branch: sasha/pile-of-law # use your branch
  # git_commit: # OR use your commit hash
  pip_install: -e .[llm]
  ssh_clone: false # Should be true if using a private repo


command: |
  cd llm-foundry/llmfoundry/inference
  # # s3 commands
  # pip install awscli
  # aws s3 cp --recursive s3://bucket/folder/hf/ local_hf_folder

  # oci commands
  pip install oci-cli
  oci os object bulk-download \
  -bn  mosaicml-internal-checkpoints --region us-phoenix-1 \
  --prefix sasha/mosaic-gpt-1b-gpus-8-Fuj0Wh/hf/ --dest-dir ./
  # oci downloads the full prefix path, this extracts the innermost folder
  # into local_hf_folder
  mv sasha/mosaic-gpt-1b-gpus-8-Fuj0Wh/hf/ local_hf_folder

  python hf_generate.py \
    --name_or_path local_hf_folder/ \
    --temperature 1.0 \
    --top_p 0.95 \
    --top_k 50 \
    --seed 1 \
    --max_new_tokens 256 \
    --prompts \
      "Write a legal document about MosaicML." \
      "How can a tenant combat a landlord illegaly trying to get them out?" \
      "What is tort in law?"

image: mosaicml/pytorch:1.13.1_cu117-python3.10-ubuntu20.04
optimization_level: 0

# Mosaic Cloud will use run_name (with a unique suffix) to populate the env var $COMPOSER_RUN_NAME
run_name: hf-generate

gpu_num: 8
cluster: vision-cluster # replace with your cluster here!
